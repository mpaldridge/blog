---
layout: post
title:  "ChatGPT takes MATH1710"
date:   2023-02-14
categories: writing
permalink: /blog/chatgpt.html
use_math: true
---

Last semester, I taught the module [MATH1710 Probability and Statistics 1](https://mpaldridge.github.io/math1710/), which is our first-year undergraduate introduction to (mostly) probability. Students took the exam in January, and the marking team and I have recently finished marking it. The median mark for the students was 47 out of 80, or 59%. A first-class mark was 56 out of 80, or 70%, which just under a third of students achieved.

I decided to give the exam to [ChatGPT](https://chat.openai.com/chat/d6c15d78-597c-4fb6-aab1-1c836c35be4f), the AI chatbot thing: I copy-pasted in the questions, one at a time, then marked ChatGPT's first response. Chat GPT scored 56 out of 80, or 70%. That means ChatGPT just sneaks a first-class mark, and would be in the top third of the class.

The exam was taken under traditionally proctored exam conditions, so I'm not concerned that students could have cheated on this particular exam. But I'm curious about how Chat GPT would do, and I'm thinking about whether I need to make changes to non-proctored take-home coursework in the furture. My opinion is that ChatGPT did pretty well -- I'd have found this difficult to believe 18 months ago -- but there still seems some low-hanging fruit I would expect it to get better at in fairly short order. (Maybe I'll try again next year, and see how much it's improved.)

Some further notes on ChatGPT's performance below, for those who are interested:

(Note: I input more complicated equations in LaTeX format, and ChatGPT often responded in LaTeX format too. For ease of reading, I've converted both of these to proper mathematical equations here. A student looking to cheat using ChatGPT, though, would be well advised to learn some basic LaTeX formatting.)

**1.** One question was a visual question:

> **Me:** What is a plausible value for the correlation $r_{xy}$ between the two datasets illustrated in the scatterplot below?
>
> A: -0.8,  B: -0.4,  C: 0,  D: 0.3,  E: 0.8.

![a scatterplot that seems to show some weak top-left-to-bottom-right association](../assets/img/scatter.png)

I couldn't work out how to enter this question into ChatGPT, so gave it 0 out of 2. Maybe coursework, especially in statistics, should make more use of "interpret this graph" type questions, as these seem much harder to cheat on using AI at the moment.
	
**2.** Despite the recent claim that ["We’ve upgraded the ChatGPT model with improved […] mathematical capabilities,"](https://help.openai.com/en/articles/6825453-chatgpt-release-notes), ChatGPT still makes fairly regular slips in basic arithmetic that, had a human made them, I would call "careless". Careless arithmetic slips cost ChatGPT 4 marks in total over four different questions.

The most obvious of these was this:

> **ChatGPT:** [...] So we have
$$p_{Y \mid X}(3 \mid 2) = \frac{p_{X,Y}(2,3)}{p_X(2)} = \frac{0.4}{0.7} = \frac{2}{3}$$
So the conditional probability of $Y=3$ given that $X=2$ is $\frac{2}{3}$.

The correct answer was indeed $\frac{0.4}{0.7}$, but that is, of course, $\frac{4}{7}$, not $\frac{2}{3}$.

ChatGPT failed to correctly perform a fairly basic definite integral:

> **Me:** A continuous random variable $X$ has probability density function $f$ given by
$$ f(x) = \begin{cases} \frac{2}{3} x & 0 \leq x < 1 , \\
1 - \frac{1}{3} x & 1 \leq x \leq 3 , \end{cases} $$
and $f(x) = 0$ otherwise. Calculate the expectation $EX$ of $X$.

> **ChatGPT:** The expectation of a continuous random variable $X$ is given by
$$EX = \int_{-\infty}^\infty x f(x) dx.$$
Therefore,
$$ \begin{align}
EX &= \int_0^1 \frac{2}{3} x^2 dx + \int_1^3 (1 - \frac{1}{3} x) x dx \\
&= \left[\frac{1}{3} x^3 \right]_0^1 + \left[\frac{3}{2}x - \frac{1}{3}x^2\right]_1^3 \\
&= \frac{1}{3} - \frac{0}{3} + \left(\frac{3}{2} \cdot 3 - \frac{1}{3} \cdot 9\right) - \left(\frac{3}{2} - \frac{1}{3} \right) \\
&= \frac{1}{3} + \frac{9}{2} - \frac{9}{3} - \frac{1}{2} \\
&= \frac{9}{6} \\
\end{align} $$
So, the expectation $EX$ of $X$ is $\frac{9}{6}$.

This is again in error. (*WHy?*) It seems there are plenty of questions where optimal cheating would be letting ChatGPT convert a wordy question into an equation, but then letting something like Wolfram Alpha actually solve (or at least check the solution of) that equation. Wolfram Alpha would breeze through the integral in the above question, no problems at all, and the user could be *confident* in its correctness.

**3.** I was surprised to see ChatGPT lose 3 marks on two straightforward bookwork questions I'd seen it answer correctly before.

> ("Using the axioms, show that P(empty set) = 0" and "Prove Bayes' theorem.")

Perhaps I was just unlucky this time – although in the second case ChatGPT seemed "distracted" by information given in the previous question that wasn't relevant to this one.
	
The exam had two "Discuss the modelling assumptions"-type questions. For one, ChatGPT gave a poor, vague answer and lost 2 marks, but for the other it gave a superbly clear and precise answer that was better than any student answer I saw.
	
It managed to correctly read information about a joint distribution from a table and perform calculations on the numbers in that table.
	
It could accurately give R code in answer to questions that required it.
	
It could deal with cross-referencing between questions (eg, "Using the same random variable as in Question 7, calculate...").
	
It generally gave more explanation and justification and steps of working than I really wanted to read through, a problem that no real student has ever presented to me in all my years of teaching.
