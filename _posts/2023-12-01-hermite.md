---
layout: post
title:  "The Hermite distribution (Falling moments III)"
date:   2023-12-01
categories: maths
permalink: /blog/hermite.html
use_math: true
---

***Previously:** [Falling moments I](falling-moments.html), [Falling and thinning (Falling moments II)](falling-thinning.html).* 

The Hermite distribution, introduced by [Kemp & Kemp](https://doi.org/10.2307/2333691), is defined like this. It is a discrete distribution on the non-negative integers. It has two parameters, $\mu$ and $\delta$, where $\mu \geq \delta \geq 0$. Now, let $Y \sim \operatorname{Po}(\mu - \delta)$ and $Z \sim \operatorname{Po}(\delta/2)$ be independent Poisson distributions; then $X = Y + 2Z$ has the Hermite distribution $X \sim \operatorname{Herm}(\mu, \delta)$.

(I'm using a different parametrisation from Kemp & Kemp and [Wikipedia](https://en.wikipedia.org/wiki/Hermite_distribution) that I think will work much more nicely in what follows.) 

It is known that a Poisson distribution $W \sim \operatorname{Po}(\mu)$ is "equidispersed", in that its expectation $\mathbb EW = \mu$ and its variance $\operatorname{Var}(W) = \mu$ are equal. But often in real life, count data is actually "overdispersed", in that its variance is bigger than its mean. The Hermite distribution is an attempt to model data that is similar to a Poisson but slightly overdispersed. Note that if $X \sim \operatorname{Herm}(\mu, \delta)$, then

$$ \begin{gather}* \mathbb EX = \mathbb EY + 2\, \mathbb EZ = (\mu - \delta) + 2 \big(\frac{\delta}{2}\big) = \mu , \\
\operatorname{Var}(X) = \operatorname{Var}(X) + 2^2 \, \operatorname{Var}(Y) = (\mu - \delta) + 2 \big(\frac{\delta}{2}\big) = \mu + \delta . \end{gather*} $$

So the variance $\mu + \delta$ is bigger than the expectation $\mu$. Note the restriction $\delta \leq \mu$ means the distribution can only be "slightly overdispersed" -- the variance can only be at most twice as big as the expectation.

But the reason that I'm interested in the Hermite distribution is that it seems to behave in many ways like a discrete (non-negative integer) version of the normal distribution. Let's look at some properties.

| Normal | Hermite |
|-|-|
| Let $X \sim \operatorname{N}(\mu, \sigma^2)$ be normally distributed with expectation $\mu$ and variance $\sigma^2$. | Let $X \sim \operatorname{Herm}(\mu, \delta)$ be Hermite distributed with expectation $\mu$ and dispersion $\delta$. |
| The expectation (first moment) is $\mathbb EX = \mu$. | The expectation (first falling moment) is $\mathbb EX = \mu$. |
| The second moment is $\mathbb EX^2 = \mu^2 + \sigma^2$. | The second falling moment is $\mathbb EX^{\underline{2}} = \mu^2 + \delta$.|
| The variance $\operatorname{Var}(X) = \mathbb EX^2 - (\mathbb EX)^2$ is $\operatorname{Var}(X) = \sigma^2$. | The dispersion $\operatorname{Disp}(X) = \mathbb EX^{\underline{2}} - (\mathbb EX)^2$ is $\operatorname{Disp}(X) = \delta$. |
| If we set the variance $\sigma^2$ to 0, then $X \sim \operatorname{N}(\mu, 0)$ is a point mass with expectation $\mu$. | If we set the dispersion $\delta$ to 0, then $X \sim \operatorname{Herm}(\mu, 0)$ is a Poisson distribution with expectation $\mu$. |
| If we scale $X$ by a scaling factor $a$, we get $aX \sim \operatorname{N}(a\mu, a^2 \sigma^2)$, where the expectation is scaled by $a$ and the variance by $a^2$. | If we thin $X$ by a thinning factor $a$, we get $a \circ X \sim \operatorname{Herm}(a\mu, a^2 \delta)$, where the expectation is scaled by $a$ and the dispersion by $a^2$. |
| If we shift $X$ by adding an independent point mass with expectation $b$, we get $X + b \sim \operatorname{N}(\mu + b, \sigma^2)$, where the expectation is shifted by $b$ and the variance stays the same. | If we shift $X$ by adding an independent Poisson distribution with expectation $b$, we get $X + \operatorname{Po}(b) \sim \operatorname{Herm}(\mu + b, \delta)$, where the expectation is shifted by $b$ and the variance stays the same. |
| If we add together two independent normal distributions $X_1 \sim \operatorname{N}(\mu_1, \sigma^2_1)$ and $X_2 \sim \operatorname{N}(\mu_2, \sigma^2_2)$, we get another normal distribution $X_1 + X_2 \sim \operatorname{N}(\mu_1 + \mu_2, \sigma^2_1 + \sigma^2_2)$ where the parameters have been added. | If we add together two independent Hermite distributions $X_1 \sim \operatorname{Herm}(\mu_1, \delta_1)$ and $X_2 \sim \operatorname{Herm}(\mu_2, \delta_2)$, we get another Hermite distribution $X_1 + X_2 \sim \operatorname{Herm}(\mu_1 + \mu_2, \delta_1 + \delta_2)$ where the parameters have been added. |
| $X$ is infinitely divisible | $X$ is infinitely divisible |
| The MGF of $X$ is $M_X(t) = \exp\big(\mu t + \tfrac12\sigma^2 t^2\big)$. | The FMGF of $X$ is $\Phi_X(t) = \exp\big(\mu t + \tfrac12\delta t^2\big)$. |
| The normal distribution features as the limiting distribution in the central limit theorem. | ??? |

*(This post was largely inspired by [this paper of JÃ¸rgensen & Kokonendji from 2015](https://doi.org/10.1007/s10182-015-0250-z), which also, it turns out, covers most, if not everything, in my previous two posts on this topic.)*
